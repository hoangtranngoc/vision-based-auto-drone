{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\git\\\\models\\\\research', 'E:\\\\git\\\\models\\\\research\\\\slim', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\python36.zip', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\DLLs', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36', '', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\hoang\\\\.ipython', 'E:\\\\git\\\\keras-resnet']\n"
     ]
    }
   ],
   "source": [
    "# import required classes\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from keras.models import load_model\n",
    "import threading\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model \n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "\n",
    "import sys\n",
    "if \"E:\\\\git\\\\keras-resnet\" not in sys.path:\n",
    "    sys.path.append(\"E:\\\\git\\\\keras-resnet\")\n",
    "    print(sys.path)\n",
    "\n",
    "import resnet\n",
    "import keras.applications\n",
    "    \n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "# configure memory allocate for tensorflow backend\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True  #dynamically grow the memory used on the GPU\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MobileNetV2_model():\n",
    "    net = MobileNetV2(input_shape=(512, 512, 3), include_top=None, weights=None, classes=nb_classes)\n",
    "    x = net.output\n",
    "\n",
    "    outputs = []\n",
    "    multi_output = 4\n",
    "\n",
    "    for i in range(multi_output):\n",
    "        pool = GlobalAveragePooling2D()(x)\n",
    "        dense = Dense(nb_classes, activation='softmax', use_bias=True)(pool)\n",
    "        outputs.append(dense)\n",
    "\n",
    "    model = Model(net.inputs, outputs=outputs, name='mobilenetv2')\n",
    "    return model\n",
    "\n",
    "def build_DenseNet121_model():\n",
    "    net = DenseNet121(input_shape=(512, 512, 3), include_top=False, weights=None, classes=nb_classes)\n",
    "    x = net.output\n",
    "\n",
    "    outputs = []\n",
    "    multi_output = 4\n",
    "    for i in range(multi_output):\n",
    "        pool = GlobalAveragePooling2D()(x)\n",
    "        dense = Dense(nb_classes, activation='softmax')(pool)\n",
    "        outputs.append(dense)\n",
    "\n",
    "    model = Model(net.inputs, outputs=outputs, name='densenet')\n",
    "    return model\n",
    "\n",
    "def build_NasnetMobile_model():\n",
    "    net = NASNetMobile(input_shape=(512, 512, 3), include_top=False, weights=None, classes=nb_classes)\n",
    "    x = net.output\n",
    "\n",
    "    outputs = []\n",
    "    multi_output = 4\n",
    "    for i in range(multi_output):\n",
    "        avg = GlobalAveragePooling2D()(x)\n",
    "        dense = Dense(nb_classes, activation='softmax')(avg)\n",
    "        outputs.append(dense)\n",
    "\n",
    "    model = Model(net.inputs, outputs=outputs, name='nasnet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 3\n",
    "\n",
    "# Resnet18\n",
    "# voa_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_resnet18_view-offset-altitude_12.hdf5')\n",
    "# cam_pitch_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_resnet18_cam-pitch_transfer-learning_08.hdf5')\n",
    "# model = resnet.ResnetBuilder.build_resnet_18_uav((3, 512, 512), nb_classes, multi_output=4)\n",
    "\n",
    "#MobileNetV2\n",
    "voa_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_mobilenetv2_view-offset-altitude_08.hdf5')\n",
    "cam_pitch_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_mobilenetv2_cam-pitch_transfer-learning_09.hdf5')\n",
    "model = build_MobileNetV2_model()\n",
    "\n",
    "# DenseNet121\n",
    "# voa_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_densenet121_view-offset-altitude_11.hdf5')\n",
    "# cam_pitch_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_densenet121_cam_pitch_transfer-learning_09.hdf5')\n",
    "# model = build_DenseNet121_model()\n",
    "\n",
    "#NasnetMobile\n",
    "# voa_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_nasnetmobile_view-offset-altitude_08.hdf5')\n",
    "# cam_pitch_model = load_model('C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\keras\\\\results\\\\model_nasnetmobile_cam_pitch_transfer-learning_17.hdf5')\n",
    "# model = build_NasnetMobile_model()\n",
    "\n",
    "w1 = voa_model.get_weights()\n",
    "w2 = cam_pitch_model.get_weights()\n",
    "w = w1 + w2[-2:]\n",
    "\n",
    "model.set_weights(w)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0000000e+00, 4.4525567e-08, 1.9623884e-18]], dtype=float32), array([[3.7051745e-07, 9.9999964e-01, 1.6780914e-09]], dtype=float32), array([[2.928667e-05, 9.999707e-01, 1.784223e-14]], dtype=float32), array([[4.6562172e-06, 9.9870706e-01, 1.2883403e-03]], dtype=float32)]\n",
      "[4.6562172e-06 9.9870706e-01 1.2883403e-03]\n",
      "[2.928667e-05 9.999707e-01 1.784223e-14]\n",
      "[1.0000000e+00 4.4525567e-08 1.9623884e-18]\n",
      "[3.7051745e-07 9.9999964e-01 1.6780914e-09]\n"
     ]
    }
   ],
   "source": [
    "def write_probs_on_image(vv_prob, height_prob, offset_prob, view_prob, vertical_angle, image_array, img_path):\n",
    "    # initialise the drawing context with\n",
    "    # the image object as background\n",
    "    img = Image.fromarray(image_array)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # create font object with the font file and specify\n",
    "    # desired size\n",
    "    font = ImageFont.truetype('Roboto-Medium.ttf', size=15)\n",
    "    \n",
    "    # OFFSET\n",
    "    (x, y) = (235, 450)\n",
    "    color = 'rgb(0, 255, 255)' \n",
    "    draw.text((x, y), 'Offset: ', fill=color, font=font)\n",
    "    \n",
    "    (x, y) = (290, 450)\n",
    "    color = 'rgb(255, 255, 0)' \n",
    "    draw.text((x, y), 'C', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(offset_prob[0])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (355, 450)\n",
    "    color = 'rgb(0, 255, 0)' #  color\n",
    "    draw.text((x, y), 'M', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(offset_prob[1])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (420, 450)\n",
    "    color = 'rgb(255, 0, 255)' #  color\n",
    "    draw.text((x, y), 'F', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(offset_prob[2])), fill=color, font=font)\n",
    "    \n",
    "    # VIEW\n",
    "    (x, y) = (235, 420)\n",
    "    color = 'rgb(0, 255, 255)' \n",
    "    draw.text((x, y), 'View: ', fill=color, font=font)\n",
    "    \n",
    "    (x, y) = (290, 420)\n",
    "    color = 'rgb(255, 255, 0)' \n",
    "    draw.text((x, y), 'L', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(view_prob[0])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (355, 420)\n",
    "    color = 'rgb(0, 255, 0)' #  color\n",
    "    draw.text((x, y), 'S', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(view_prob[1])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (420, 420)\n",
    "    color = 'rgb(255, 0, 255)' #  color\n",
    "    draw.text((x, y), 'R', fill=color, font=font)\n",
    "    draw.text((x+15, y), str(\"{0:.3f}\".format(view_prob[2])), fill=color, font=font)\n",
    "    \n",
    "    # HEIGHT\n",
    "    # starting position of the message\n",
    "    (x, y) = (300, 300)\n",
    "    color = 'rgb(0, 255, 255)' \n",
    "    draw.text((x, y), 'Altitude: ', fill=color, font=font)\n",
    "    \n",
    "    (x, y) = (300, 320)\n",
    "    color = 'rgb(255, 255, 0)' \n",
    "    draw.text((x, y), 'H', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(height_prob[2])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (300, 340)\n",
    "    color = 'rgb(0, 255, 0)' #  color\n",
    "    draw.text((x, y), 'M', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(height_prob[1])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (300, 360)\n",
    "    color = 'rgb(255, 0, 255)' #  color\n",
    "    draw.text((x, y), 'L', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(height_prob[0])), fill=color, font=font)\n",
    "    \n",
    "    # VERTICAL_VIEW\n",
    "    # starting position of the message\n",
    "    (x, y) = (400, 300)\n",
    "    color = 'rgb(0, 255, 255)' \n",
    "    draw.text((x, y), 'Vertical-View: ', fill=color, font=font)\n",
    "    \n",
    "    (x, y) = (400, 320)\n",
    "    color = 'rgb(255, 255, 0)' \n",
    "    draw.text((x, y), 'U', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(vv_prob[2])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (400, 340)\n",
    "    color = 'rgb(0, 255, 0)' #  color\n",
    "    draw.text((x, y), 'M', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(vv_prob[1])), fill=color, font=font)\n",
    "\n",
    "    (x, y) = (400, 360)\n",
    "    color = 'rgb(255, 0, 255)' #  color\n",
    "    draw.text((x, y), 'D', fill=color, font=font)\n",
    "    draw.text((x+20, y), str(\"{0:.3f}\".format(vv_prob[0])), fill=color, font=font)\n",
    "\n",
    "    # VERTICAL_VIEW\n",
    "    # starting position of the message\n",
    "    (x, y) = (400, 250)\n",
    "    color = 'rgb(0, 255, 255)' \n",
    "    draw.text((x, y), 'Vertical-Angle: ', fill=color, font=font)\n",
    "    color = 'rgb(255, 160, 16)' \n",
    "    draw.text((x+20, y+20), str(\"{0:.1f}\".format(vertical_angle)), fill=color, font=font)\n",
    "    \n",
    "    \n",
    "    # save the edited image\n",
    "    #print(img_path)\n",
    "    img.save(img_path)\n",
    "\n",
    "f = 'E:\\\\UAV_drone\\\\data\\\\2019-01-04-6groups_120fov_height_normal\\\\val\\\\medium\\\\img_0_0_1546559335497177700.png'\n",
    "# f = 'img_0_0_1546722126943805600.png'\n",
    "img = imread(f) \n",
    "img_rgb = img[:,:,:3]\n",
    "img_norm = img_rgb / 255.0\n",
    "img_final = np.reshape(img_norm,[1,512,512,3])\n",
    "probs = model.predict(img_final)\n",
    "print (probs)\n",
    "offset_prob = probs[0][0]\n",
    "view_prob = probs[1][0]\n",
    "height_prob = probs[2][0]\n",
    "pitch_prob = probs[3][0]\n",
    "print(pitch_prob)\n",
    "print(height_prob)\n",
    "print(offset_prob)\n",
    "print(view_prob)\n",
    "img_path = os.path.join('.' , 'prob_'+'.png')\n",
    "write_probs_on_image(pitch_prob, height_prob, offset_prob, view_prob, 0, img_rgb, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rain_values = [0, 0.5, 1]\n",
    "snow_values = [0, 0.5, 1]\n",
    "fog_values = [0, 0.25, 0.5, 0.75, 1]\n",
    "mapleleaf_values = [0, 0, 0, 0, 0.25, 0.5]\n",
    "dust_values = [0, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "def setWeather(rain=0, snow=0, fog=0, mapleleaf=0, dust=0, isRandom=False):\n",
    "    client.simEnableWeather(True)   \n",
    "    if isRandom:\n",
    "        r = random.choice(rain_values)\n",
    "        s = random.choice(snow_values)\n",
    "        f = random.choice(fog_values)\n",
    "        l = random.choice(mapleleaf_values)\n",
    "        d = random.choice(dust_values)   \n",
    "    else:\n",
    "        r = rain\n",
    "        s = snow\n",
    "        f = fog\n",
    "        l = mapleleaf\n",
    "        d = dust\n",
    "    \n",
    "    print (\"r{}, s{}, f{}, l{}, d{}\".format(r,s,f,l,d))\n",
    "    client.simSetWeatherParameter(airsim.WeatherParameter.Rain, r)\n",
    "    client.simSetWeatherParameter(airsim.WeatherParameter.Snow, s)\n",
    "    client.simSetWeatherParameter(airsim.WeatherParameter.Fog, f)\n",
    "    client.simSetWeatherParameter(airsim.WeatherParameter.MapleLeaf, l)\n",
    "    client.simSetWeatherParameter(airsim.WeatherParameter.Dust, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherList = [[1.0, 1.0, 0.25, 0.0, 0.25],\n",
    "               [0.0, 0.0, 0.75, 0.0, 0.0],\n",
    "               [0.0, 0.0, 0.25, 0.75, 0.25],\n",
    "               [0.0, 0.0, 0.0, 0.0, 0.75],\n",
    "               [0.5, 0.5, 0.5, 0.5, 0.5]]\n",
    "\n",
    "\n",
    "FLYING_LOG_DIR = \"E:\\\\UAV_drone\\\\Logs\\\\flying_recording_play_arounddfsdfdfsfsdfgfdfdd\"\n",
    "\n",
    "if not os.path.exists(FLYING_LOG_DIR):\n",
    "    os.makedirs(FLYING_LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: image})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.int64)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict\n",
    "\n",
    "PATH_TO_FROZEN_GRAPH = 'C:\\\\Users\\\\hoang\\\\WorkingSpace\\\\TrainingModels\\\\object_detection\\\\models\\\\frozen_inference_graph.pb'\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\git\\\\models\\\\research', 'E:\\\\git\\\\models\\\\research\\\\slim', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\python36.zip', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\DLLs', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36', '', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\hoang\\\\.ipython', 'E:\\\\git\\\\keras-resnet', 'E:\\\\git\\\\AirSim\\\\PythonClient']\n",
      "-- ['E:\\\\git\\\\models\\\\research', 'E:\\\\git\\\\models\\\\research\\\\slim', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\python36.zip', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\DLLs', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36', '', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages', 'C:\\\\Users\\\\hoang\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\tf36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\hoang\\\\.ipython', 'E:\\\\git\\\\keras-resnet', 'E:\\\\git\\\\AirSim\\\\PythonClient']\n"
     ]
    }
   ],
   "source": [
    "import common_functions as control\n",
    "from common_types import *\n",
    "import airsim\n",
    "from airsim.types import *\n",
    "\n",
    "import pprint\n",
    "import time\n",
    "import math\n",
    "\n",
    "def transform_input_for_detection(responses, detection_graph):\n",
    "    response = responses[0]\n",
    "    img1d_rgba = np.frombuffer(response.image_data_uint8, dtype=np.uint8)\n",
    "    img4d_rgba = img1d_rgba.reshape(512, 512, 4)\n",
    "    img3d_rbg = img4d_rgba[:, :, :3] #512*512*3\n",
    "    \n",
    "    img3d_rbg_reshape = np.reshape(img3d_rbg,[1,512,512,3])\n",
    "    ### insulator detection ###\n",
    "    capture_points = detect_objects(img3d_rbg_reshape, detection_graph, 4)\n",
    "    \n",
    "    return capture_points\n",
    "\n",
    "def transform_input(responses, vertical_angle, i, f, recording=False, vertical_view_only = False):\n",
    "   \n",
    "    response = responses[0]\n",
    "    img1d_rgba = np.frombuffer(response.image_data_uint8, dtype=np.uint8)\n",
    "    img4d_rgba = img1d_rgba.reshape(512, 512, 4)\n",
    "    img3d_rbg = img4d_rgba[:, :, :3] #512*512*3\n",
    "    \n",
    "    img3d_rbg_reshape = np.reshape(img3d_rbg,[1,512,512,3])\n",
    "    img_final = img3d_rbg_reshape/255.\n",
    "    \n",
    "    #height_prob = vertical_model.predict(img_final)[0]\n",
    "    probs = model.predict(img_final)\n",
    "    offset_prob = probs[0][0]\n",
    "    view_prob = probs[1][0]\n",
    "    height_prob = probs[2][0]  \n",
    "    pitch_prob = probs[3][0]\n",
    "    \n",
    "    if (recording): \n",
    "        img_name = 'prob_'+str(i)+'.png'\n",
    "        img_path = os.path.join(FLYING_LOG_DIR , img_name)\n",
    "        #imsave(img, img3d_rbg)\n",
    "        write_probs_on_image(pitch_prob, height_prob, offset_prob, view_prob, -vertical_angle, img3d_rbg, img_path)\n",
    "    \n",
    "    ### Mast detection ###\n",
    "    mast_detections = detect_objects(img3d_rbg_reshape, detection_graph, 4) #replace 4(insulator) to 1(mast) when mast detection is ok\n",
    "    \n",
    "    \n",
    "    return (pitch_prob, height_prob, offset_prob, view_prob, mast_detections)\n",
    "\n",
    "def getPitchRollYawInRad():\n",
    "    return airsim.to_eularian_angles(client.simGetGroundTruthKinematics().orientation)\n",
    "\n",
    "def getZ():\n",
    "    return client.simGetGroundTruthKinematics().position.z_val\n",
    "\n",
    "def toDegree(rad):\n",
    "    return rad*180.0/math.pi\n",
    "\n",
    "def toRad(angle):\n",
    "    return angle*math.pi/180.0\n",
    "\n",
    "def moveByYawPitch(cur_yaw_rad, new_yaw_rad, z, cur_z, angle, velocity, headless= False, file=None, recording=False): \n",
    "    yaw = cur_yaw_rad + new_yaw_rad\n",
    "    \n",
    "    gv = (velocity - z*math.tan(angle)) * math.cos(angle)\n",
    "    z_new = (velocity-z*math.tan(angle)) * math.sin(angle) + z/math.cos(angle)\n",
    "       \n",
    "    vx = gv*math.cos(yaw)\n",
    "    vy = gv*math.sin(yaw)\n",
    "      \n",
    "    if recording == True:\n",
    "        file.write('headless {}, vx {:.3f}, vy {:.3f}, z_new {:.3f}, yaw {}\\n'.format(headless, vx, vy, z_new, -toDegree(new_yaw_rad)))\n",
    "    \n",
    "    if headless == True:\n",
    "        client.moveByVelocityZAsync(vx, vy, cur_z+z_new, 0.2, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,-toDegree(new_yaw_rad))).join()\n",
    "    else:\n",
    "        client.moveByVelocityZAsync(vx, vy, cur_z+z_new, 0.2, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "\n",
    "def capture_images(client, object_type_name, i):\n",
    "    responses = client.simGetImages([airsim.ImageRequest(\"0\", airsim.ImageType.Scene, False, False)])\n",
    "    response = responses[0]\n",
    "\n",
    "    # get numpy array\n",
    "    img1d = np.frombuffer(response.image_data_uint8, dtype=np.uint8) \n",
    "\n",
    "    # reshape array to 4 channel image array H X W X 4\n",
    "    img_rgb = img1d.reshape(response.height, response.width, 4)\n",
    "\n",
    "    # original image is fliped vertically\n",
    "    img_rgb = np.flipud(img_rgb)\n",
    "\n",
    "    # write to png \n",
    "    airsim.write_png(os.path.normpath('captures/' + object_type_name + str(i) +'.png'), img_rgb) \n",
    "\n",
    "def detect_objects(img3d_rbg_reshape, detection_graph, object_id):\n",
    "    output_dict = run_inference_for_single_image(img3d_rbg_reshape, detection_graph)\n",
    "    n = output_dict['num_detections']\n",
    "        \n",
    "    capture_points = []\n",
    "    for j in range (0,n):\n",
    "        if output_dict['detection_scores'][j] > 0.5: \n",
    "            print (\"iter-{}: {}, {}, {}\\n\".format(i, output_dict['detection_classes'][j], \n",
    "                                         output_dict['detection_scores'][j], \n",
    "                                         output_dict['detection_boxes'][j]))\n",
    "            class_id = output_dict['detection_classes'][j]\n",
    "            if class_id == object_id:\n",
    "                capture_points.append(output_dict['detection_boxes'][j])\n",
    "                \n",
    "    return capture_points\n",
    "\n",
    "def cal_yaw_change_for_detection(coords):\n",
    "    x = (coords[1] + coords[3])/2\n",
    "    print (x)\n",
    "    new_yaw_rad = math.atan((0.5-x)/(0.577*0.5)) # tan(30degree) = 0.577\n",
    "    new_yaw_degree = toDegree (new_yaw_rad_1)\n",
    "    print (new_yaw_degree) \n",
    "    return new_yaw_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Client Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n",
      "\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# connect to the AirSim simulator\n",
    "client = airsim.MultirotorClient()\n",
    "client.confirmConnection()\n",
    "client.enableApiControl(True)\n",
    "client.armDisarm(True)\n",
    "# takeoff\n",
    "client.takeoffAsync().join()\n",
    "client.moveToZAsync(-1, 1).join()\n",
    "\n",
    "vertical_angle = 0\n",
    "client.simSetCameraOrientation(\"0\", airsim.to_quaternion(toRad(-45 - vertical_angle), 0, 0)) # down 45 degree \n",
    "print('test')\n",
    "# client.simSetCameraOrientation(\"0\", airsim.to_quaternion(-0.5236, 0, 0)) # down 30 degree \n",
    "# client.simSetCameraOrientation(\"0\", airsim.to_quaternion(-0.08727, 0, 0)) # down 15 degree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "27.471304980740648\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def toDegree(rad):\n",
    "    return rad*180.0/math.pi\n",
    "\n",
    "print('test')\n",
    "x = 0.35\n",
    "new_yaw_rad_1 = math.atan((0.5-x)/(0.577*0.5)) # tan(30degree) = 0.577\n",
    "new_yaw_degree_1 = toDegree (new_yaw_rad_1)\n",
    "print (new_yaw_degree_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-0: 4, 0.9854394197463989, [0.3662891  0.30443874 0.42115596 0.3672025 ]\n",
      "\n",
      "iter-0: 4, 0.8818758726119995, [0.36949944 0.20409991 0.42158544 0.2688345 ]\n",
      "\n",
      "iter-0: 3, 0.7687592506408691, [0.00761697 0.00428891 0.36481962 0.98157525]\n",
      "\n",
      "0.33582061529159546\n",
      "27.471304980740648\n",
      "iter-0: 3, 0.8581703305244446, [5.4784119e-04 2.6605219e-02 3.5587966e-01 1.0000000e+00]\n",
      "\n",
      "iter-0: 4, 0.6923450827598572, [0.36290306 0.5006753  0.4125551  0.552125  ]\n",
      "\n",
      "iter-1: 4, 0.9938367009162903, [0.3329078 0.3225479 0.387353  0.3789705]\n",
      "\n",
      "iter-1: 4, 0.8398850560188293, [0.33104092 0.21851754 0.38447452 0.29026884]\n",
      "\n",
      "iter-1: 3, 0.8146003484725952, [0.00521189 0.0060015  0.33476162 0.9637742 ]\n",
      "\n",
      "0.35075920820236206\n",
      "27.471304980740648\n",
      "iter-1: 3, 0.9883679747581482, [0.42615458 0.26324654 0.590116   0.5448009 ]\n",
      "\n",
      "iter-1: 4, 0.9743846654891968, [0.46813676 0.44555482 0.5265161  0.5007308 ]\n",
      "\n",
      "iter-1: 4, 0.9328581094741821, [0.39203778 0.2687595  0.4385983  0.3314991 ]\n",
      "\n",
      "iter-1: 4, 0.8902230858802795, [0.42348328 0.34527117 0.48070684 0.40437448]\n",
      "\n",
      "iter-1: 3, 0.7001573443412781, [0.         0.01633424 0.39927194 0.9958777 ]\n",
      "\n",
      "iter-1: 7, 0.6187875270843506, [0.3944417  0.30370915 0.43498614 0.38059658]\n",
      "\n",
      "iter-2: 4, 0.9952051639556885, [0.38599744 0.22130984 0.44202057 0.28521043]\n",
      "\n",
      "iter-2: 4, 0.9757698178291321, [0.3812743  0.11206992 0.4345933  0.18475635]\n",
      "\n",
      "iter-2: 3, 0.7761244177818298, [0.         0.00923979 0.33224052 0.98461604]\n",
      "\n",
      "iter-2: 7, 0.6494773626327515, [0.3897815  0.13268866 0.42293188 0.2039376 ]\n",
      "\n",
      "0.25326013565063477\n",
      "27.471304980740648\n",
      "iter-2: 4, 0.98968505859375, [0.5109233  0.3196962  0.5675431  0.38914466]\n",
      "\n",
      "iter-2: 4, 0.9269264340400696, [0.46545854 0.23685485 0.5169107  0.3034311 ]\n",
      "\n",
      "iter-3: 4, 0.9947322607040405, [0.46633893 0.20778175 0.5279498  0.2894866 ]\n",
      "\n",
      "iter-3: 4, 0.9753465056419373, [0.45165232 0.08171578 0.5122462  0.17327861]\n",
      "\n",
      "iter-3: 4, 0.9693461060523987, [0.47220248 0.3626638  0.54492086 0.43161112]\n",
      "\n",
      "iter-3: 3, 0.6588461995124817, [0.         0.00845981 0.38556856 1.        ]\n",
      "\n",
      "0.24863415956497192\n",
      "27.471304980740648\n",
      "iter-3: 4, 0.9689719080924988, [0.5566441  0.11250421 0.64688945 0.21238333]\n",
      "\n",
      "iter-3: 4, 0.9651349186897278, [0.6838783  0.1972216  0.7793654  0.29446357]\n",
      "\n",
      "iter-3: 2, 0.553506076335907, [0.03402382 0.00887485 0.6919642  0.2370708 ]\n",
      "\n",
      "iter-4: 4, 0.9840348958969116, [0.6097224  0.13088185 0.70345795 0.25154036]\n",
      "\n",
      "iter-4: 2, 0.6001313328742981, [0.01613995 0.00882235 0.6886635  0.25467965]\n",
      "\n",
      "iter-4: 4, 0.5571885108947754, [0.6429845  0.36130524 0.7447778  0.44972324]\n",
      "\n",
      "iter-4: 3, 0.5455816984176636, [0.         0.01456127 0.32557756 0.9712384 ]\n",
      "\n",
      "0.19121110439300537\n",
      "27.471304980740648\n",
      "iter-4: 2, 0.54337078332901, [0.0611608  0.         0.8833386  0.22976759]\n",
      "\n",
      "iter-12: 3, 0.509178876876831, [0.00266606 0.         0.3102516  0.96228564]\n",
      "\n",
      "iter-17: 3, 0.5269643664360046, [0.00151971 0.01277751 0.30221254 0.9811913 ]\n",
      "\n",
      "iter-20: 3, 0.5339407920837402, [0.00270142 0.0119113  0.30866212 0.97582996]\n",
      "\n",
      "iter-34: 3, 0.6930989027023315, [0.00210276 0.00938919 0.31413248 0.9692035 ]\n",
      "\n",
      "iter-35: 3, 0.7111932635307312, [0.         0.00996521 0.33828086 0.95568514]\n",
      "\n",
      "iter-51: 3, 0.5054156184196472, [0.         0.02022052 0.27880687 0.9668326 ]\n",
      "\n",
      "iter-52: 3, 0.5325251221656799, [1.3056397e-04 8.7845623e-03 2.7699810e-01 9.7101331e-01]\n",
      "\n",
      "iter-56: 3, 0.5034933090209961, [0.         0.01197895 0.27983183 0.9539826 ]\n",
      "\n",
      "iter-57: 3, 0.5810608863830566, [0.         0.01623234 0.276533   0.96080005]\n",
      "\n",
      "iter-59: 3, 0.5174752473831177, [0.00107804 0.01251259 0.29794294 0.9564084 ]\n",
      "\n",
      "iter-61: 3, 0.5178546905517578, [0.00815798 0.0050146  0.2986666  0.9780853 ]\n",
      "\n",
      "iter-62: 3, 0.5108476281166077, [0.00813758 0.007963   0.28361174 0.9864472 ]\n",
      "\n",
      "iter-63: 3, 0.7090129852294922, [1.0021523e-02 8.8101625e-04 3.1963396e-01 9.4854242e-01]\n",
      "\n",
      "iter-64: 4, 0.9763827323913574, [0.36598542 0.08886813 0.4256737  0.1802796 ]\n",
      "\n",
      "iter-64: 3, 0.6829606294631958, [0.01611993 0.         0.37500057 0.97322845]\n",
      "\n",
      "0.13457386195659637\n",
      "27.471304980740648\n",
      "Press enter to stop flying: \n",
      "iter-68: 3, 0.5463340878486633, [0.         0.00438654 0.29820198 0.9952958 ]\n",
      "\n",
      "stopped at  69\n"
     ]
    }
   ],
   "source": [
    "#client.simSetCameraOrientation(\"0\", airsim.to_quaternion(-0.5235, 0, 0)) #radians\n",
    "#home_location = client.simGetGroundTruthKinematics().position\n",
    "name = os.path.join(FLYING_LOG_DIR, \"logs.txt\")\n",
    "f = open(name, \"a+\")\n",
    "\n",
    "recording = False\n",
    "\n",
    "\n",
    "change_pitch_count = 0\n",
    "total_z_angle_prob = 0\n",
    "\n",
    "user_input = []\n",
    "\n",
    "# spawn a new thread to wait for input \n",
    "def get_user_input(user_input):\n",
    "    input(\"Press enter to stop flying: \")\n",
    "    user_input.append(None)\n",
    "\n",
    "mythread = threading.Thread(target=get_user_input, args=(user_input,))\n",
    "mythread.daemon = True\n",
    "mythread.start()\n",
    "\n",
    "adjust_camera_enable = True\n",
    "\n",
    "i = 0\n",
    "while True:    \n",
    "#     if (i%50==0):\n",
    "#         (r, s, fo, l, d) = weatherList[int(i/50)%4]\n",
    "#         setWeather(r, s, fo, l, d)\n",
    "        \n",
    "    _, _, cur_yaw_rad = getPitchRollYawInRad()\n",
    "    cur_yaw_degree = toDegree(cur_yaw_rad)\n",
    "    cur_z = getZ()\n",
    "    f.write('{}, cur_yaw {:.3f}, cur_z {:.3f}\\n'.format(i, cur_yaw_degree, cur_z))\n",
    "    \n",
    "    responses = client.simGetImages([airsim.ImageRequest(0, airsim.ImageType.Scene, False, False)])\n",
    "    pitch_prob, height_prob, offset_prob, view_prob, mast_detections  = transform_input(responses, vertical_angle, i, f, recording)      \n",
    "\n",
    "    ### objects detected ###\n",
    "    if len(mast_detections) > 0:     \n",
    "        new_yaw_degree_tmp = cal_yaw_change_for_detection(mast_detections[0])\n",
    "                      \n",
    "        # stop, rotate to mast\n",
    "        client.moveByVelocityZAsync(0, 0, getZ()-0.25, 0.005, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "        client.hoverAsync().join()\n",
    "        client.rotateToYawAsync(cur_yaw_degree - new_yaw_degree_tmp, 1, 1).join()\n",
    "        client.hoverAsync().join()\n",
    "        \n",
    "        # capture mast\n",
    "        capture_images(client, \"mast\", i)\n",
    "        \n",
    "        # TODO find other objects (now is a insulator)\n",
    "        responses = client.simGetImages([airsim.ImageRequest(0, airsim.ImageType.Scene, False, False)])\n",
    "        capture_points = transform_input_for_detection(responses, detection_graph)\n",
    "        j=0\n",
    "        for point in capture_points:\n",
    "            # rotate to insulator    \n",
    "            client.rotateToYawAsync(cur_yaw_degree - new_yaw_degree_tmp, 1, 1).join()\n",
    "            client.hoverAsync().join()\n",
    "            # capture insulator\n",
    "            capture_images(client, \"mast\"+str(i)+\"ins\", j)\n",
    "            j+=1\n",
    "        \n",
    "        # done, back to the inital angle\n",
    "        client.rotateToYawAsync(cur_yaw_degree, 1, 1).join()\n",
    "        \n",
    "    ################################    \n",
    "    \n",
    "    z_angle_prob = pitch_prob[0] - pitch_prob[2] # down - up \n",
    "\n",
    "    # check and raise the camera\n",
    "    if adjust_camera_enable == True:\n",
    "        if (abs(z_angle_prob)>0.5):        \n",
    "            change_pitch_count += 1\n",
    "            total_z_angle_prob += z_angle_prob\n",
    "            if (recording):\n",
    "                f.write('{}, change_pitch_count {},  total_z_angle_prob {}, vertical_angle is {:.3f}\\n'.format(i,change_pitch_count, total_z_angle_prob, vertical_angle))\n",
    "\n",
    "            if (change_pitch_count >= 3):\n",
    "\n",
    "                vertical_angle += -(total_z_angle_prob/change_pitch_count)*10\n",
    "                client.simSetCameraOrientation(\"0\", airsim.to_quaternion(toRad(-45 - vertical_angle), 0, 0)) \n",
    "\n",
    "                change_pitch_count = 0\n",
    "                total_z_angle_prob = 0\n",
    "\n",
    "        else:\n",
    "            change_pitch_count = 0\n",
    "            total_z_angle_prob = 0\n",
    "            \n",
    "    # navigate\n",
    "    z_offset_2 = 0.4*(height_prob[0] - height_prob[2]) # low - high\n",
    "    new_z = z_offset_2\n",
    "    \n",
    "    if ((height_prob[0] > 0.95 or height_prob[2] >0.95) and (adjust_camera_enable == False or abs(vertical_angle) >= 25.0)):\n",
    "        #double move higher or lower\n",
    "        new_z *= 1.5\n",
    "    \n",
    "    latoff_angle = 10 * (offset_prob[0] - offset_prob[2]) # left - right\n",
    "    \n",
    "    view_angle = 0\n",
    "    view_angle = 10 * (view_prob[0] - view_prob[2])\n",
    "    headless = False \n",
    "    \n",
    "    if (view_prob[1] >= 0.99):\n",
    "        headless = True       \n",
    "    \n",
    "    new_yaw_degree =  view_angle + latoff_angle \n",
    "    \n",
    "    if (recording):\n",
    "        f.write('{}, added_yaw {:.3f}, added_z {:.3f}, z_angle_prob {:.3f}\\n'.format(i, new_yaw_degree, new_z, z_angle_prob))\n",
    "        f.write('{}, view_angle {:.3f}, latoff_angle {:.3f}\\n'.format(i, view_angle, latoff_angle))\n",
    "          \n",
    "    \n",
    "    if (headless == False and (new_yaw_degree > 10.5 or new_yaw_degree < -10.5)):\n",
    "        if (recording):\n",
    "            f.write('****turning with a BIG ANGLE\\n')\n",
    "        #double rotate in this case\n",
    "        client.rotateToYawAsync(cur_yaw_degree + new_yaw_degree, 1, 1).join()\n",
    "   \n",
    "    if adjust_camera_enable == True:\n",
    "        velocity = 0.25*pitch_prob[1] + 0.25*offset_prob[1] + 0.25*view_prob[1] + 0.25*height_prob[1]\n",
    "    else:\n",
    "        velocity = 0.333*offset_prob[1] + 0.333*view_prob[1] + 0.333*height_prob[1]\n",
    "    new_yaw_rad = toRad(new_yaw_degree)\n",
    "    _, _, cur_yaw_rad = getPitchRollYawInRad()\n",
    "    \n",
    "    cur_yaw_degree = toDegree(cur_yaw_rad)\n",
    "    cur_z = getZ()\n",
    "    f.write('{}, cur_yaw {:.3f}, cur_z {:.3f}\\n'.format(i, cur_yaw_degree, cur_z))\n",
    "    \n",
    "    moveByYawPitch(cur_yaw_rad, new_yaw_rad, -new_z, cur_z, toRad(vertical_angle), velocity, headless, file=f, recording=True)\n",
    "    \n",
    "    i+=1\n",
    "    if user_input:\n",
    "        break \n",
    "\n",
    "print (\"stopped at \", i)\n",
    "#work around to make drone stop\n",
    "client.moveByVelocityZAsync(0, 0, getZ()-0.25, 0.005, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "client.hoverAsync().join()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.moveByVelocityAsync(-1, 0, 0, 5, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "# client.moveByVelocityAsync(-1, -1, 0, 5, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "# client.moveByVelocityAsync(-1, -1, -1, 5, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "\n",
    "# client.moveByAngleZAsync(pitch=1, roll=0, yaw=1)\n",
    "# client.simGetObjectPose(\"H_mast_ins_brown_4_white_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervention code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(name, \"a+\")\n",
    "f.write('intervention, moving drone back to proper position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shilf right\n",
    "new_yaw_rad = toRad(90)\n",
    "_, _, cur_yaw_rad = getPitchRollYawInRad()\n",
    "cur_yaw_degree = toDegree(cur_yaw_rad)\n",
    "cur_z = getZ()\n",
    "name = os.path.join(FLYING_LOG_DIR, \"logs.txt\")\n",
    "\n",
    "moveByYawPitch(cur_yaw_rad, new_yaw_rad, 0, cur_z, toRad(vertical_angle), velocity, True, file=f, recording=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.moveByVelocityZAsync(0, 0, getZ()-0.25, 0.005, drivetrain=DrivetrainType.ForwardOnly, yaw_mode = YawMode(False,0)).join()\n",
    "client.hoverAsync().join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate\n",
    "_, _, cur_yaw_rad = getPitchRollYawInRad()\n",
    "cur_yaw_degree = toDegree(cur_yaw_rad)\n",
    "new_yaw_degree =  90\n",
    "client.rotateToYawAsync(cur_yaw_degree + new_yaw_degree, 1, 1).join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b9d4355d5bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# move higher 1 m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveToZAsync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetZ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf36\\lib\\site-packages\\msgpackrpc\\future.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf36\\lib\\site-packages\\msgpackrpc\\loop.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \"\"\"\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ioloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf36\\lib\\site-packages\\tornado\\ioloop.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                     \u001b[0mevent_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                     \u001b[1;31m# Depending on python version and IOLoop implementation,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tf36\\lib\\site-packages\\tornado\\platform\\select.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         readable, writeable, errors = select.select(\n\u001b[1;32m---> 63\u001b[1;33m             self.read_fds, self.write_fds, self.error_fds, timeout)\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# move higher 1 m\n",
    "client.moveToZAsync(getZ()-1, 1).join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust camera\n",
    "vertical_angle = 0\n",
    "client.simSetCameraOrientation(\"0\", airsim.to_quaternion(toRad(-45 - vertical_angle), 0, 0)) # down 45 degree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write('done intervention'.format(i, cur_yaw_degree, cur_z))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
